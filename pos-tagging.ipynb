{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part o Speech Tagging of Portugese Sentences\n",
        "\n",
        "Part of speech (PoS) taggins is a fundamental technique in most natural language recognition projects, in which we try to determine the role each word plays on a sentence. For example, the sentence \"Toto, I have a feeling that we are not in Kansas anymore.\" could be tagged as:\n",
        "\n",
        "| Word    | Tag         |\n",
        "|---------|-------------|\n",
        "| Toto    | Proper noun |\n",
        "| ,       | Punctuation |\n",
        "| I       | Pronoun     |\n",
        "| have    | Verb        |\n",
        "| a       | Determiner  |\n",
        "| feeling | Noun        |\n",
        "| that    | Preposition |\n",
        "| we      | Pronoun     |\n",
        "| are     | Verb        |\n",
        "| not     | Adverb      |\n",
        "| in      | Preposition |\n",
        "| Kansas  | Noun        |\n",
        "| anymore | Adverb      |\n",
        "| .       | Punctuation |\n",
        "\n",
        "However, on this notebook, we will be performing PoS tagging over portuguese sentences, as english PoS tagging has already been covered in many other projects. Therefore, this discussion will be carried out in portuguese from this point onwards.\n",
        "\n",
        "If you want to learn about PoS tagging in english, you can read [this article](https://medium.com/data-science-in-your-pocket/pos-tagging-using-hidden-markov-models-hmm-viterbi-algorithm-in-nlp-mathematics-explained-d43ca89347c4) by Mehul Gupta who does a job that is honestly better than mine on explaining the topic in detail. You can also easily find [many implementations of PoS tagging on GitHub](https://github.com/search?q=pos-tagging)."
      ],
      "metadata": {
        "id": "p83fiRwv_piw"
      },
      "id": "p83fiRwv_piw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hidden Markov Model\n",
        "\n",
        "Nesses exemplos, usaremos a implementação do algoritmo _Hidden Markov Model_ (Modelo Oculto de Markov) oferecido pela biblioteca `nltk`. Esse modelo tem diversas aplicações além de _PoS tagging_ em áreas como termodinâmica, estatística, ecnomia, teoria da informação, entre outras.\n",
        "\n",
        "Teremos um processo estocástico, mais especificamente um processo Markoviano, ou seja, temos uma sequência de variáveis aleatórias que podem assumir um conjunto de estados $Q$ onde a probabilidade de cada estado depende apenas do estado assumido na variável anterior, chamaremos essa sequência de $X$. Teremos também uma senquência de valores observáveis $Y$ onde a ocorrência de $y_n$ está relacionada com a ocorrência de $x_n$. Baseado nisso teremos duas tabelas de probabilidade: as probabilidades de transição e as probabilidades de emissão. As probabilidades de transição indicam a probabilidade de $x_n$ assumir um dado estado baseado no estado de $x_{n-1}$:\n",
        "\n",
        "$$P(x_n|x_{n-1})$$\n",
        "\n",
        "Enquanto as probabilidades de emissão indicam a probabilidade de um observável $y_n$ ser emitido por um estado $q$:\n",
        "\n",
        "$$P(y_n|x_n)$$\n",
        "\n",
        "No nosso caso, os estados assumíveis serão classes de palavras existentes na língua portugesa que aqui serão representados com: \n",
        "\n",
        "| Classe de palavra                      | Tag        |\n",
        "|----------------------------------------|------------|\n",
        "| Artigo                                 | ART        |\n",
        "| Adjetivo                               | ADJ        |\n",
        "| Nome                                   | N          |\n",
        "| Nome próprio                           | NPROP      |\n",
        "| Numeral                                | NUM        |\n",
        "| Pronome adjetivo                       | PROADJ     |\n",
        "| Pronome substantivo                    | PROSUB     |\n",
        "| Pronome pessoal                        | PROPESS    |\n",
        "| Pronome conectivo subordinado          | PRO-KS     |\n",
        "| Pronome conectivo subordinado relativo | PRO-KS-REL |\n",
        "| Advérbio                               | ADV        |\n",
        "| Advérbio conectivo subordinativo       | ADV-KS     |\n",
        "| Advérbio relativo subordinativo        | ADV-KS-REL |\n",
        "| Conjunção coordenativa                 | KC         |\n",
        "| Conjunção subordinativa                | KS         |\n",
        "| Preposição                             | PREP       |\n",
        "| Interjeição                            | IN         |\n",
        "| Verbo                                  | V          |\n",
        "| Verbo auxiliar                         | VAUX       |\n",
        "| Particípio                             | PCP        |\n",
        "| Palavra denotativa                     | PDEN       |\n",
        "| Pontuação.                             | PU         |\n",
        "| Moeda corrente                         | CUR        |\n",
        "\n",
        "as tags ainda podem ser acompanhadas de informações adicionais denotadas por:\n",
        "\n",
        "| Informação            | Modificador (_TAG_\\|MOD) |\n",
        "|-----------------------|--------------------------|\n",
        "| Estrangeirismo        | EST                      |\n",
        "| Apostos               | AP                       |\n",
        "| Dados                 | DAD                      |\n",
        "| Números de telefone   | TEL                      |\n",
        "| Datas                 | DAT                      |\n",
        "| Horas                 | HOR                      |\n",
        "| Contrações e ênclises | +                        |\n",
        "| Mesóclise             | !                        |\n",
        "\n",
        "\n",
        "A sequência $X$ será a sequência de tags atribuídas a uma sentença fornecida e a sequência $Y$ será composta das palavras que formam a sentença. Ou seja, teremos que as probabilidades de transição serão probabilidades de que uma classe de palavra seja precedida por outra, enquanto as probabilidades de emissão serão as probabilidades de que uma determinada palavra tenha o papel de uma determinada classe de discurso. Por exemplo, suponha que tenhamos apenas três classes de palavras: nomes, verbos e advérbios, uma possível tabela de probabilidades de transição seria:\n",
        "\n",
        "|              | **Nome** | **Verbo** | **Advérbio** |\n",
        "|--------------|----------|-----------|--------------|\n",
        "| **Nome**     | 0.6      | 0.1       | 0.3          |\n",
        "| **Verbo**    | 0.5      | 0.1       | 0.4          |\n",
        "| **Advérbio** | 0.5      | 0.4       | 0.1          |\n",
        "\n",
        "caso o nosso vocabulário possua apenas as palavras armando, faz e rapidamente, uma possível tabela de probabilidades de emissão seria:\n",
        "\n",
        "|                 | **Nome** | **Verbo** | **Advérbio** |\n",
        "|-----------------|----------|-----------|--------------|\n",
        "| **Armando**     | 0.5      | 0.5       | 0.0          |\n",
        "| **Faz**         | 0.1      | 0.9       | 0.0          |\n",
        "| **Rapidamente** | 0.0      | 0.0       | 1.0          |\n",
        "\n",
        "O _Hidden Markov Model_ monta uma máquina de estados e trabalha com iterações baseadas nas duas probabilidades mencionadas para convergir e determinar uma classificação adequada para as palavras de uma sentença. Essas probabilidades são calculadas a partir de uma análise dos dados de treino fornecidos. Veremos agora o exemplo utilizando a implementação da `nltk` do algoritmo."
      ],
      "metadata": {
        "id": "YTavZH50eNqg"
      },
      "id": "YTavZH50eNqg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementação"
      ],
      "metadata": {
        "id": "Fg6lOUUP9q6C"
      },
      "id": "Fg6lOUUP9q6C"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e6ac2406",
      "metadata": {
        "id": "e6ac2406"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from typing import Tuple\n",
        "from matplotlib import pyplot as plt\n",
        "from nltk.tag.hmm import HiddenMarkovModelTrainer\n",
        "from nltk.tag import HiddenMarkovModelTagger\n",
        "from random import randint\n",
        "from pandas import DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizaremos o corpus disponível [nesse link](http://nilc.icmc.usp.br/macmorpho/macmorpho-v3.tgz) cuja documentação pode ser obtida [aqui](http://nilc.icmc.usp.br/macmorpho/macmorpho-manual.pdf)."
      ],
      "metadata": {
        "id": "vdRNY28d9m2j"
      },
      "id": "vdRNY28d9m2j"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a74880ff",
      "metadata": {
        "id": "a74880ff"
      },
      "outputs": [],
      "source": [
        "corpus_train_path = './macmorpho-train.txt'\n",
        "corpus_test_path = './macmorpho-test.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função `read_tags` recebe o caminho para o arquivo e realiza o pré processamento do texto. Em primeiro lugar, colocamos todo o texto em letras minúsculas para evitar problemas. Em seguida observamos o formato do corpus que é uma sequência de tokens `PALAVRA_TAG` separados por espaço ou quebra de linha, então substituímos todos as quebras de linha por espaços e fazemos um split nesses espaços para separar esses tokens. Então fazemos um split por \"_\" para criar tuplas `(PALAVRA, TAG)`. Por fim, separamos o texto em sentenças assumindo que sentenças terminam em \".\", \"!\" ou \"?\".\n",
        "\n",
        "A função `read_sentence_text` é um helper que converte um vetor de tuplas na frase original."
      ],
      "metadata": {
        "id": "vzVpCyLG9_2t"
      },
      "id": "vzVpCyLG9_2t"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "687474e7",
      "metadata": {
        "id": "687474e7"
      },
      "outputs": [],
      "source": [
        "def read_tags(corpus_path: str):\n",
        "    corpus_file = open(corpus_path, encoding='utf-8')\n",
        "    corpus = corpus_file.read().replace('\\n', ' ').lower()\n",
        "    words = [tuple(word_tag.split('_')) for word_tag in corpus.split(' ')]\n",
        "    \n",
        "    sentences = [[]]\n",
        "    sentence_terminators = ['.', '!', '?']\n",
        "    for word in words:\n",
        "        sentences[-1].append(word)\n",
        "        if word[0] in sentence_terminators:\n",
        "            sentences.append([])\n",
        "    sentences.pop()        \n",
        "    \n",
        "    return sentences\n",
        "\n",
        "def read_sentence_text(sentence: list):\n",
        "    return ' '.join([word[0] for word in sentence])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Então pre-processamos nosso corpus e treinamos o modelo com a classe `HiddenMarkovModelTrainer` do módulo `hmm` da `nltk`."
      ],
      "metadata": {
        "id": "fnfnzEkmAEpI"
      },
      "id": "fnfnzEkmAEpI"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8de119a7",
      "metadata": {
        "id": "8de119a7"
      },
      "outputs": [],
      "source": [
        "sentences = read_tags(corpus_train_path)\n",
        "trainer = HiddenMarkovModelTrainer()\n",
        "tagger = trainer.train_supervised(sentences[:34724])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um exemplo da nossa organização dos dados é apresentado abaixo:"
      ],
      "metadata": {
        "id": "9cKOr0k1AViC"
      },
      "id": "9cKOr0k1AViC"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5e4fc4e8",
      "metadata": {
        "id": "5e4fc4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "44688adf-cbb5-427c-cf02-3bd4789d8ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase:\n",
            "em seguida vêm os produtos matinais , com 51,3 % em um mês .\n",
            "Representação:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-288e6480-74e8-4237-b353-8bc7f36ca065\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>em</td>\n",
              "      <td>adv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>seguida</td>\n",
              "      <td>adv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>vêm</td>\n",
              "      <td>v</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>os</td>\n",
              "      <td>art</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>produtos</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>matinais</td>\n",
              "      <td>adj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>,</td>\n",
              "      <td>pu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>com</td>\n",
              "      <td>prep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>51,3</td>\n",
              "      <td>num</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>%</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>em</td>\n",
              "      <td>prep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>um</td>\n",
              "      <td>num</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>mês</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>.</td>\n",
              "      <td>pu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-288e6480-74e8-4237-b353-8bc7f36ca065')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-288e6480-74e8-4237-b353-8bc7f36ca065 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-288e6480-74e8-4237-b353-8bc7f36ca065');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           0     1\n",
              "0         em   adv\n",
              "1    seguida   adv\n",
              "2        vêm     v\n",
              "3         os   art\n",
              "4   produtos     n\n",
              "5   matinais   adj\n",
              "6          ,    pu\n",
              "7        com  prep\n",
              "8       51,3   num\n",
              "9          %     n\n",
              "10        em  prep\n",
              "11        um   num\n",
              "12       mês     n\n",
              "13         .    pu"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "sentence_index = randint(0, len(sentences))\n",
        "print(\"Frase:\")\n",
        "print(read_sentence_text(sentences[sentence_index]))\n",
        "print(\"Representação:\")\n",
        "DataFrame(sentences[sentence_index])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o modelo treinado, podemos realizar amostras de classificações para palavras com as funções abaixo."
      ],
      "metadata": {
        "id": "ZlvQNuHdCVeE"
      },
      "id": "ZlvQNuHdCVeE"
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_word(word: str):\n",
        "  return tagger.tag([word.lower()])[0][1]\n",
        "\n",
        "def tag_sentence(sentence: str):\n",
        "  return tagger.tag_sents([sentence.split(' ')])[0]\n",
        "\n",
        "def print_tag(word: str):\n",
        "  print(f'{word}:', tag_word(word))"
      ],
      "metadata": {
        "id": "fvcm52MNEVAy"
      },
      "id": "fvcm52MNEVAy",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Palavras:"
      ],
      "metadata": {
        "id": "P8TpTw-MGJPe"
      },
      "id": "P8TpTw-MGJPe"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7657f4ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7657f4ba",
        "outputId": "fcd389c0-a2bb-42cd-c186-023e025eaecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fugiu: v\n",
            "escritório: n\n",
            "rapidamente: adv\n",
            "R$: cur\n",
            "armando: nprop\n",
            "seu: proadj\n",
            "feliz: nprop\n"
          ]
        }
      ],
      "source": [
        "print_tag('fugiu')\n",
        "print_tag('escritório')\n",
        "print_tag('rapidamente')\n",
        "print_tag('R$')\n",
        "print_tag('armando')\n",
        "print_tag('seu')\n",
        "print_tag('feliz')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentenças:"
      ],
      "metadata": {
        "id": "WaHbLCFHGK58"
      },
      "id": "WaHbLCFHGK58"
    },
    {
      "cell_type": "code",
      "source": [
        "tag_sentence('mesmo estando atrasado , parou para cumprimentá-lo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ-7pCEZGR7l",
        "outputId": "62360d36-507d-470b-de81-644b15912cfc"
      },
      "id": "VJ-7pCEZGR7l",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mesmo', 'pden'),\n",
              " ('estando', 'v'),\n",
              " ('atrasado', 'pcp'),\n",
              " (',', 'pu'),\n",
              " ('parou', 'v'),\n",
              " ('para', 'prep'),\n",
              " ('cumprimentá-lo', 'n')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "beda5d6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beda5d6e",
        "outputId": "dde558e6-9d70-44cb-e24c-b7143019dcff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('o', 'art'),\n",
              " ('galo', 'n'),\n",
              " ('ganhou', 'v'),\n",
              " ('mais', 'adv'),\n",
              " ('uma', 'art'),\n",
              " ('vez', 'n'),\n",
              " (',', 'pu'),\n",
              " ('ai', 'in'),\n",
              " ('credo', 'n')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "tag_sentence('o galo ganhou mais uma vez , ai credo')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_sentence('que a força esteja com você')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG8-HtLpHXLw",
        "outputId": "f80dcbbd-b71e-4626-c912-fe16230a3a02"
      },
      "id": "SG8-HtLpHXLw",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('que', 'ks'),\n",
              " ('a', 'art'),\n",
              " ('força', 'n'),\n",
              " ('esteja', 'v'),\n",
              " ('com', 'prep'),\n",
              " ('você', 'propess')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testes do modelo\n",
        "\n",
        "Agora que entendemos de modo geral a ideia de como o _Hidden Markov Model_ funciona e temos um modelo treinado, podemos verificar se o método realmente funciona.\n",
        "\n",
        "Vamos utilizar o conjunto de dados de teste incluso no corpus para testar a qualidade do modelo. A função `test_model` testa os resultados preditos pelo modelo em relação as respostas dos dados de teste e retorna o número de acertos, o número de erros e uma tabela que mostra como as predições se relacionam com as respostas corretas."
      ],
      "metadata": {
        "id": "On-2XTPFHW3E"
      },
      "id": "On-2XTPFHW3E"
    },
    {
      "cell_type": "code",
      "source": [
        "tags = [\n",
        "        \"ART\", \"ADJ\", \"N\", \"NPROP\", \"PROADJ\", \"PROSUB\",\n",
        "        \"PROPESS\", \"PRO-KS\", \"ADV\", \"ADV-KS\", \"KC\", \"KS\",\n",
        "        \"PREP\", \"IN\", \"V\", \"PCP\", \"PDEN\", \"CUR\", \"NUM\", \"PU\"\n",
        "       ]\n",
        "\n",
        "def get_tag_type(tagged_word: Tuple[str, str]):\n",
        "  tag = tagged_word[1]\n",
        "  if '|' in tag:\n",
        "    tag = tag.split('|')[0]\n",
        "  if '+' in tag:\n",
        "    tag = tag.split('+')[0]\n",
        "  return tag.upper()\n",
        "\n",
        "def test_model(tagger: HiddenMarkovModelTagger, predictions: list, test_sentences: list):\n",
        "  hit = 0\n",
        "  miss = 0\n",
        "  results = DataFrame(data=[[0 for tag in tags] for tag in tags], columns=tags, index=[tags])\n",
        "  for i in range(len(predictions)):\n",
        "    for j in range(len(predictions[i])):\n",
        "      prediction = get_tag_type(predictions[i][j])\n",
        "      answer = get_tag_type(test_sentences[i][j])\n",
        "      if(prediction == answer):\n",
        "        hit += 1\n",
        "      else:\n",
        "        miss += 1\n",
        "      results[answer][prediction] += 1\n",
        "\n",
        "  return (hit, miss, results)"
      ],
      "metadata": {
        "id": "aeUto33yKPPh"
      },
      "id": "aeUto33yKPPh",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = read_tags(corpus_test_path)\n",
        "predictions = tagger.tag_sents([[word[0] for word in sentence] for sentence in test_sentences])\n",
        "hit, miss, result = test_model(tagger, predictions, test_sentences)"
      ],
      "metadata": {
        "id": "5cqAV47pN9Xq"
      },
      "id": "5cqAV47pN9Xq",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos verificar, o modelo acertou 119.585 classificações enquanto errou 58.788 delas, isso representa uma taxa de acerto de aproximadamente 67%, o que é uma taxa razoável especialmente considerando que ela poderia provavelmente ser melhorada com ajustes nos parâmetros de treino."
      ],
      "metadata": {
        "id": "2vhY2-PDX1xh"
      },
      "id": "2vhY2-PDX1xh"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Acertos:', hit)\n",
        "print('Erros:', miss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heCOFig0IA51",
        "outputId": "0032cd3f-fdaf-41b4-dce8-9cb5f80685a3"
      },
      "id": "heCOFig0IA51",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acertos: 116743\n",
            "Erros: 61630\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo observamos os resultados obtidos no teste, as linhas representam a predição enquanto as colunas representam a resposta correta para a palavra. Podemos perceber que o erro mais comum é a classificação incorreta de palavras como nomes, isso provavelmente é devido ao fato dos nomes serem uma classe de palavras mais geral que as outras, portanto, pela característica do aprendizado de máquina, quando o modelo não sabe qual classe atribuir a uma palavra, ele tende a optar por uma classificação menos específica. "
      ],
      "metadata": {
        "id": "Ev4KvGapcGTi"
      },
      "id": "Ev4KvGapcGTi"
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_csv('./test-result.csv')\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "EzcZSFXjXvS5",
        "outputId": "a55f25b7-06c3-4780-e3a6-3bebb29c0b35"
      },
      "id": "EzcZSFXjXvS5",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2de673dc-b182-423d-8ab5-782f6b09ff5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ART</th>\n",
              "      <th>ADJ</th>\n",
              "      <th>N</th>\n",
              "      <th>NPROP</th>\n",
              "      <th>PROADJ</th>\n",
              "      <th>PROSUB</th>\n",
              "      <th>PROPESS</th>\n",
              "      <th>PRO-KS</th>\n",
              "      <th>ADV</th>\n",
              "      <th>ADV-KS</th>\n",
              "      <th>KC</th>\n",
              "      <th>KS</th>\n",
              "      <th>PREP</th>\n",
              "      <th>IN</th>\n",
              "      <th>V</th>\n",
              "      <th>PCP</th>\n",
              "      <th>PDEN</th>\n",
              "      <th>CUR</th>\n",
              "      <th>NUM</th>\n",
              "      <th>PU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ART</th>\n",
              "      <td>8624</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>96</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>199</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADJ</th>\n",
              "      <td>0</td>\n",
              "      <td>4318</td>\n",
              "      <td>382</td>\n",
              "      <td>247</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>N</th>\n",
              "      <td>3804</td>\n",
              "      <td>4078</td>\n",
              "      <td>35458</td>\n",
              "      <td>8384</td>\n",
              "      <td>1237</td>\n",
              "      <td>403</td>\n",
              "      <td>854</td>\n",
              "      <td>923</td>\n",
              "      <td>1750</td>\n",
              "      <td>96</td>\n",
              "      <td>1924</td>\n",
              "      <td>762</td>\n",
              "      <td>10402</td>\n",
              "      <td>40</td>\n",
              "      <td>6753</td>\n",
              "      <td>1647</td>\n",
              "      <td>328</td>\n",
              "      <td>80</td>\n",
              "      <td>947</td>\n",
              "      <td>12100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NPROP</th>\n",
              "      <td>14</td>\n",
              "      <td>79</td>\n",
              "      <td>395</td>\n",
              "      <td>6641</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PROADJ</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>2031</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PROSUB</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>868</td>\n",
              "      <td>1</td>\n",
              "      <td>74</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PROPESS</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRO-KS</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>134</td>\n",
              "      <td>14</td>\n",
              "      <td>1091</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>181</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADV</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>21</td>\n",
              "      <td>13</td>\n",
              "      <td>37</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3140</td>\n",
              "      <td>2</td>\n",
              "      <td>54</td>\n",
              "      <td>42</td>\n",
              "      <td>182</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADV-KS</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KC</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>2502</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KS</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>89</td>\n",
              "      <td>60</td>\n",
              "      <td>51</td>\n",
              "      <td>15</td>\n",
              "      <td>1319</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PREP</th>\n",
              "      <td>110</td>\n",
              "      <td>6</td>\n",
              "      <td>35</td>\n",
              "      <td>431</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>223</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>77</td>\n",
              "      <td>16677</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IN</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>36</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>12901</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PCP</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>49</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1968</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PDEN</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>634</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CUR</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>215</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NUM</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>131</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1491</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PU</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14804</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2de673dc-b182-423d-8ab5-782f6b09ff5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2de673dc-b182-423d-8ab5-782f6b09ff5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2de673dc-b182-423d-8ab5-782f6b09ff5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          ART   ADJ      N  NPROP  PROADJ  ...   PCP  PDEN  CUR   NUM     PU\n",
              "ART      8624     0      3     96       3  ...     0     0    0    91      0\n",
              "ADJ         0  4318    382    247      14  ...    15     3    0     0      0\n",
              "N        3804  4078  35458   8384    1237  ...  1647   328   80   947  12100\n",
              "NPROP      14    79    395   6641       3  ...     5     0    1     5      0\n",
              "PROADJ      0    10     10     12    2031  ...     0     5    0     0      0\n",
              "PROSUB     19     1      4      2      48  ...     0     4    0     4      0\n",
              "PROPESS     1     0      0      5       1  ...     0     0    0     0      0\n",
              "PRO-KS      3     1      0      2       8  ...     0     3    0     0      0\n",
              "ADV         1    20     21     13      37  ...     0    42    0     2      0\n",
              "ADV-KS      0     0      0      0       0  ...     0     0    0     0      0\n",
              "KC          0     0      3     33       0  ...     0    17    0     0      0\n",
              "KS          0     1      6      0      21  ...     0     6    0     0      0\n",
              "PREP      110     6     35    431       5  ...     0    37    0     1      0\n",
              "IN          0     8      3      5       2  ...     2     2    0     0      0\n",
              "V           0    11     36     32       0  ...     3    11    0     0      0\n",
              "PCP         0    16     49     10       0  ...  1968     0    0     0      0\n",
              "PDEN        0     2      6      0       9  ...     0   634    0     0      0\n",
              "CUR         0     0      0      2       0  ...     0     0  215     0      0\n",
              "NUM         4     3    131     12       0  ...     0     0    0  1491      0\n",
              "PU          0     0      0      9       0  ...     0     0    0     0  14804\n",
              "\n",
              "[20 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No gráfico abaixo podemos ver como essa característica está refletida na taxa de acertos dos nomes que é muito próxima de 1, em mais de 90% dos casos o modelo classifica nomes corretamente."
      ],
      "metadata": {
        "id": "Pt5Dz1Hxi20x"
      },
      "id": "Pt5Dz1Hxi20x"
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = [result[tag][tag]/(result[tag].sum()) for tag in tags]\n",
        "plt.figure(figsize=(22, 10))\n",
        "plt.bar(tags, accuracies, .9)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "-Kww3zt8fm5P",
        "outputId": "7a9eca61-ba55-4354-b9ee-c6236f860cce"
      },
      "id": "-Kww3zt8fm5P",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1584x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outro ponto interessante a se notar, é que as classes de palavras mais comuns como artigos, nomes, pronomes e verbos têm as maiores acuracias, cerca de 70% em todos os casos, o que significa que nos casos mais comuns, a classificação é eficaz. Moedas também apresentaram uma boa precisão, provavelmente devido ao fato de que representações de moedas tendem a ser mais específicas, já que são um grupo muito restrito e frequentemente incluem caracteres que não estão contidos no alfabeto da língua portugesa. Dentre as classes com menor precisão, podemos comentar que os nomes próprios muitas vezes são confundidos com nomes pelos modelos, possivlemente porque deixamos todo o texto em letras minúsculas no nosso pré processamento de dados. Outra classe com baixa precisão são as interjeições, que frequentemente serão palavras também utilizadas em outros contextos."
      ],
      "metadata": {
        "id": "4YkqqNggjpyW"
      },
      "id": "4YkqqNggjpyW"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "name": "pos-tagging.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}